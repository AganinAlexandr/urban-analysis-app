#!/usr/bin/env python3
"""
–û—Ç–ª–∞–¥–æ—á–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–∞
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import pandas as pd
from app.core.text_analyzer import TextAnalyzer

def debug_analysis():
    """–û—Ç–ª–∞–¥–∫–∞ –∞–Ω–∞–ª–∏–∑–∞"""
    
    print("üîç –û–¢–õ–ê–î–ö–ê –ê–ù–ê–õ–ò–ó–ê –¢–ï–ö–°–¢–ê")
    print("=" * 60)
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    test_data = {
        'group': ['hospital', 'school'],
        'name': ['–ì–ö–ë ‚Ññ 29', '–®–∫–æ–ª–∞ ‚Ññ 1'],
        'address': ['—É–ª. –õ–µ–Ω–∏–Ω–∞, 1', '—É–ª. –ü—É—à–∫–∏–Ω–∞, 10'],
        'review_text': [
            '–û—á–µ–Ω—å —Ö–æ—Ä–æ—à–∞—è –ø–æ–ª–∏–∫–ª–∏–Ω–∏–∫–∞. –í–µ–∂–ª–∏–≤—ã–π –ø–µ—Ä—Å–æ–Ω–∞–ª.',
            '–ü–ª–æ—Ö–æ–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ, –¥–æ–ª–≥–∏–µ –æ—á–µ—Ä–µ–¥–∏.'
        ],
        'rating': [5, 2],
        'date': ['2024-01-15', '2024-01-16']
    }
    
    df = pd.DataFrame(test_data)
    
    print("üìä –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:")
    print(f"  - –ó–∞–ø–∏—Å–µ–π: {len(df)}")
    print(f"  - –ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
    print()
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
    print("1Ô∏è‚É£ –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞...")
    text_analyzer = TextAnalyzer()
    analyzed_df = text_analyzer.analyze_dataframe(df)
    
    print(f"   ‚úÖ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(analyzed_df)} –∑–∞–ø–∏—Å–µ–π")
    print(f"   üìä –ö–æ–ª–æ–Ω–∫–∏ –ø–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞: {list(analyzed_df.columns)}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
    print("\n2Ô∏è‚É£ –î–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞:")
    for i, row in analyzed_df.iterrows():
        print(f"   –ó–∞–ø–∏—Å—å {i}:")
        print(f"     - group: {row.get('group', 'N/A')}")
        print(f"     - review_text: {row.get('review_text', 'N/A')[:50]}...")
        print(f"     - sentiment: {row.get('sentiment', 'N/A')}")
        print(f"     - sentiment_score: {row.get('sentiment_score', 'N/A')}")
        print(f"     - review_type: {row.get('review_type', 'N/A')}")
        print(f"     - positive_words_count: {row.get('positive_words_count', 'N/A')}")
        print(f"     - negative_words_count: {row.get('negative_words_count', 'N/A')}")
        print(f"     - is_complex_part: {row.get('is_complex_part', 'N/A')}")
        print(f"     - part_index: {row.get('part_index', 'N/A')}")
        print()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∏–µ –∑–∞–ø–∏—Å–∏ –∏–º–µ—é—Ç –ø–æ–ª—è –∞–Ω–∞–ª–∏–∑–∞
    print("3Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–µ–π –∞–Ω–∞–ª–∏–∑–∞:")
    analysis_fields = ['sentiment', 'sentiment_score', 'review_type', 'positive_words_count', 'negative_words_count']
    
    for field in analysis_fields:
        if field in analyzed_df.columns:
            non_null_count = analyzed_df[field].notna().sum()
            total_count = len(analyzed_df)
            print(f"   - {field}: {non_null_count}/{total_count} ({non_null_count/total_count*100:.1f}%)")
        else:
            print(f"   - {field}: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∑–∞–ø–∏—Å–∏ –±–µ–∑ –ø–æ–ª–µ–π –∞–Ω–∞–ª–∏–∑–∞
    print("\n4Ô∏è‚É£ –ó–∞–ø–∏—Å–∏ –±–µ–∑ –ø–æ–ª–µ–π –∞–Ω–∞–ª–∏–∑–∞:")
    missing_analysis = []
    for i, row in analyzed_df.iterrows():
        missing_fields = []
        for field in analysis_fields:
            if field in analyzed_df.columns and pd.isna(row[field]):
                missing_fields.append(field)
        if missing_fields:
            missing_analysis.append((i, missing_fields))
    
    if missing_analysis:
        print(f"   –ù–∞–π–¥–µ–Ω–æ {len(missing_analysis)} –∑–∞–ø–∏—Å–µ–π —Å –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–º–∏ –ø–æ–ª—è–º–∏ –∞–Ω–∞–ª–∏–∑–∞:")
        for idx, fields in missing_analysis:
            print(f"     - –ó–∞–ø–∏—Å—å {idx}: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç {fields}")
    else:
        print("   –í—Å–µ –∑–∞–ø–∏—Å–∏ –∏–º–µ—é—Ç –ø–æ–ª—è –∞–Ω–∞–ª–∏–∑–∞")

if __name__ == "__main__":
    debug_analysis() 